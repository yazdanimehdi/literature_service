# Literature Review Service Configuration
#
# This file contains non-secret configuration values. Values can be overridden
# using environment variables with the LITREVIEW_ prefix.
#
# Example: LITREVIEW_DATABASE_HOST=db.example.com
#          LITREVIEW_SERVER_HTTP_PORT=8888
#
# IMPORTANT: API keys and secrets must be set via environment variables only.
# See .env.example for the full list of secret environment variables.

# Server configuration
server:
  # Host address to bind the server to
  host: "0.0.0.0"
  # HTTP server port
  http_port: 8080
  # gRPC server port
  grpc_port: 9090
  # Metrics server port (Prometheus)
  metrics_port: 9091
  # Maximum duration for reading request body
  read_timeout: 30s
  # Maximum duration for writing response
  write_timeout: 30s
  # Maximum duration to wait for graceful shutdown
  shutdown_timeout: 30s

# Database configuration (PostgreSQL)
database:
  # PostgreSQL server hostname
  host: localhost
  # PostgreSQL server port
  port: 5432
  # Database username
  user: litreview
  # Database password (use LITREVIEW_DATABASE_PASSWORD env var in production)
  password: ""
  # Database name
  name: literature_review_service
  # SSL mode: disable, require, verify-ca, verify-full
  # Default is "require" for production security
  # Use LITREVIEW_DATABASE_SSL_MODE=disable for local development
  ssl_mode: require
  # Maximum number of connections in the pool
  max_conns: 50
  # Minimum number of connections to keep open
  min_conns: 10
  # Maximum lifetime of a connection
  max_conn_lifetime: 1h
  # Maximum idle time for a connection
  max_conn_idle_time: 30m
  # Interval between health checks of idle connections
  health_check_period: 30s
  # Maximum time to wait for a connection
  connect_timeout: 10s
  # Path to migration files
  migration_path: migrations
  # Enable automatic migration on startup
  migration_auto_run: false
  # Size of prepared statement cache
  statement_cache_capacity: 512

# Temporal workflow orchestration
temporal:
  # Temporal server address
  host_port: localhost:7233
  # Temporal namespace
  namespace: literature-review
  # Task queue name for literature review workflows
  task_queue: literature-review-tasks

# Logging configuration
logging:
  # Log level: trace, debug, info, warn, error, fatal, panic
  level: info
  # Log format: json, console
  format: json
  # Log output: stdout, stderr, or file path
  output: stdout
  # Add source file and line to log output
  add_source: false
  # Timestamp format
  time_format: "2006-01-02T15:04:05Z07:00"

# Prometheus metrics
metrics:
  # Enable metrics collection and exposure
  enabled: true
  # HTTP path for metrics endpoint
  path: /metrics

# OpenTelemetry distributed tracing
tracing:
  # Enable distributed tracing
  enabled: false
  # OTLP collector endpoint (required when enabled)
  endpoint: ""
  # Service name for traces
  service_name: literature-review-service
  # Sampling rate (0.0 to 1.0)
  sample_rate: 0.1

# LLM configuration for keyword extraction
# API keys are loaded exclusively from environment variables (see .env.example).
llm:
  # LLM provider: openai, anthropic, azure, bedrock, gemini, vertex
  provider: azure
  # Maximum number of keywords to extract
  max_keywords: 10
  # Minimum number of keywords to extract
  min_keywords: 5
  # Number of recursive expansion levels
  expansion_depth: 2
  # Timeout for LLM API calls
  timeout: 60s
  # Maximum retries for failed calls
  max_retries: 3
  # Base delay between retries
  retry_delay: 2s
  # LLM temperature setting
  temperature: 0.7

  # OpenAI settings (API key via LITREVIEW_LLM_OPENAI_API_KEY env var)
  openai:
    model: gpt-4-turbo
    base_url: https://api.openai.com/v1

  # Anthropic settings (API key via LITREVIEW_LLM_ANTHROPIC_API_KEY env var)
  anthropic:
    model: claude-3-sonnet-20240229
    base_url: https://api.anthropic.com

  # Embedding provider (defaults to same as chat provider above).
  # Set to use a different provider for vector embeddings.
  # Supported: openai, azure, bedrock, gemini, vertex
  embedding_provider: azure
  # Embedding model name
  embedding_model: text-embedding-3-small

  # Azure OpenAI settings (API key via LITREVIEW_LLM_AZURE_API_KEY env var)
  # Endpoint: https://{resource_name}.openai.azure.com
  azure:
    # Azure resource name (determines the endpoint URL)
    resource_name: "helixir1-resource"
    # Deployment name for chat completions (e.g. "gpt-4o")
    deployment_name: "gpt-5-mini"
    api_version: "2024-08-01-preview"
    # Model name for response metadata
    model: "gpt-5-mini"
    # Deployment name for embeddings (e.g. "text-embedding-3-small")
    # Falls back to deployment_name if empty.
    embedding_deployment_name: "text-embedding-3-small"
    # Embedding model name for response metadata
    # Falls back to embedding_deployment_name if empty.
    embedding_model: "text-embedding-3-small"

  # AWS Bedrock settings (uses AWS credentials from environment/instance profile)
  bedrock:
    region: us-east-1
    model: ""

  # Google Gemini / Vertex AI settings (API key via LITREVIEW_LLM_GEMINI_API_KEY env var)
  # For Vertex AI mode: set project + location and leave API key unset.
  # For Gemini API mode: set API key.
  gemini:
    project: ""
    location: us-central1
    model: gemini-2.0-flash

  # Resilience settings (rate limiter + circuit breaker)
  resilience:
    # Enable the resilience middleware
    enabled: false
    # Rate limiter: requests per second
    rate_limit_rps: 10.0
    # Rate limiter: burst size
    rate_limit_burst: 20
    # Rate limiter: minimum RPS during backoff
    rate_limit_min_rps: 1.0
    # Rate limiter: recovery window in seconds after backoff
    rate_limit_recovery_sec: 60
    # Circuit breaker: consecutive failures before circuit opens
    cb_consecutive_threshold: 5
    # Circuit breaker: failure rate (0.0-1.0) before circuit opens
    cb_failure_rate_threshold: 0.5
    # Circuit breaker: rolling window size for failure rate
    cb_window_size: 20
    # Circuit breaker: seconds to wait before probing after open
    cb_cooldown_sec: 30
    # Circuit breaker: probe requests in half-open state
    cb_probe_count: 3

# Kafka configuration for outbox pattern
kafka:
  # Enable Kafka publishing
  enabled: false
  # Kafka broker addresses
  brokers:
    - localhost:9092
  # Topic for outbox events
  topic: events.outbox.literature_review_service
  # Maximum messages to batch before sending
  batch_size: 100
  # Maximum time to wait for a batch to fill
  batch_timeout: 10ms

# Outbox processor configuration
outbox:
  # How often to poll for pending events
  poll_interval: 1s
  # Number of events to process per batch
  batch_size: 100
  # Number of concurrent publish workers
  workers: 4
  # Maximum retry attempts before dead-lettering
  max_retries: 5
  # How long a worker holds a lease on claimed events
  lease_duration: 30s

# Paper source API configurations
# API keys are loaded exclusively from environment variables (see .env.example).
paper_sources:
  # Semantic Scholar API
  semantic_scholar:
    enabled: true
    base_url: https://api.semanticscholar.org/graph/v1
    timeout: 30s
    rate_limit: 1.0  # requests per second
    max_results: 100

  # OpenAlex API
  openalex:
    enabled: true
    base_url: https://api.openalex.org
    timeout: 30s
    rate_limit: 10.0
    max_results: 200

  # Scopus API (disabled by default - requires API key)
  scopus:
    enabled: true
    base_url: https://api.elsevier.com/content
    timeout: 30s
    rate_limit: 5.0
    max_results: 100

  # PubMed API (E-utilities)
  pubmed:
    enabled: true
    base_url: https://eutils.ncbi.nlm.nih.gov/entrez/eutils
    timeout: 30s
    rate_limit: 3.0  # NCBI recommends max 3 req/sec without API key
    max_results: 100

  # bioRxiv API
  biorxiv:
    enabled: true
    base_url: https://api.biorxiv.org
    timeout: 30s
    rate_limit: 5.0
    max_results: 100

  # arXiv API
  arxiv:
    enabled: true
    base_url: https://export.arxiv.org/api
    timeout: 30s
    rate_limit: 3.0  # arXiv recommends max 3 req/sec
    max_results: 100

# Ingestion Service client configuration
ingestion_service:
  # gRPC address of the ingestion service
  address: localhost:9095
  # Timeout for gRPC calls
  timeout: 30s
  # Enable TLS for gRPC connection
  tls: false

# Qdrant vector store configuration for semantic dedup
qdrant:
  # Qdrant gRPC address
  address: localhost:6334
  # Collection name for paper embeddings
  collection_name: paper_embeddings
  # Embedding vector size (must match embedding model)
  vector_size: 1536
  # Cosine similarity threshold for dedup (0.0-1.0)
  similarity_threshold: 0.95
  # Author overlap threshold for dedup (0.0-1.0)
  author_threshold: 0.5
  # Number of candidates to check
  top_k: 5

# Workflow execution configuration
workflow:
  # Search phase configuration
  search:
    retry_policy:
      initial_interval: 2s
      backoff_coefficient: 2.0
      maximum_interval: 1m
      maximum_attempts: 5
    # Per-source rate limits (requests per second)
    rate_limits:
      semantic_scholar: 100.0
      openalex: 10.0
      pubmed: 3.0

  # Child workflow configuration
  child_workflow:
    retry_policy:
      initial_interval: 5s
      backoff_coefficient: 2.0
      maximum_interval: 2m
      maximum_attempts: 3

  # Embedding activity configuration
  embedding:
    retry_policy:
      initial_interval: 1s
      backoff_coefficient: 2.0
      maximum_interval: 30s
      maximum_attempts: 5

  # Dedup activity configuration
  dedup:
    retry_policy:
      initial_interval: 500ms
      backoff_coefficient: 2.0
      maximum_interval: 10s
      maximum_attempts: 3
    # Continue without dedup if all retries exhausted
    skip_on_failure: true

  # Ingestion activity configuration
  ingestion:
    retry_policy:
      initial_interval: 2s
      backoff_coefficient: 2.0
      maximum_interval: 1m
      maximum_attempts: 5
    # Max retries for PDF download per paper
    pdf_download_attempts: 3
    # Max retries for stream upload per paper
    stream_upload_attempts: 3

  # Timeout settings
  timeouts:
    # Max wait for child workflow to signal completion
    child_workflow_completion: 10m
    # Time before flushing partial batch
    batch_accumulation: 5s
    # Timeout for search activities
    search_activity: 5m
    # Timeout for embedding activities
    embedding_activity: 2m
    # Timeout for dedup activities
    dedup_activity: 1m
    # Timeout for ingestion activities
    ingestion_activity: 5m

  # Paper batching configuration
  batching:
    # Number of papers per batch
    batch_size: 5
    # Time to wait before flushing partial batch
    batch_timeout: 5s
